{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Only for Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9eeWUhAWRFcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2548a174-32d5-4932-fdfc-b2b8e34693cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_JOzZG-LMbNi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as nnF\n",
        "import torchtext.functional as F\n",
        "import torch.nn as nn\n",
        "import torchtext.transforms as T\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "\n",
        "class NN_Predictor:\n",
        "  def __init__(self, model_path):\n",
        "    self.model_path = model_path\n",
        "    self.padding_idx = 1\n",
        "    self.bos_idx = 0\n",
        "    self.eos_idx = 2\n",
        "    self.max_seq_len = 256\n",
        "    self.xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
        "    self.xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
        "\n",
        "    self.text_transform = T.Sequential(\n",
        "        T.SentencePieceTokenizer(self.xlmr_spm_model_path),\n",
        "        T.VocabTransform(load_state_dict_from_url(self.xlmr_vocab_path)),\n",
        "        T.Truncate(self.max_seq_len - 2),\n",
        "        T.AddToken(token=self.bos_idx, begin=True),\n",
        "        T.AddToken(token=self.eos_idx, begin=False),\n",
        "    )\n",
        "    self.vocab = self.text_transform[1].vocab.vocab\n",
        "    self.word_to_idx = self.vocab.get_stoi()\n",
        "\n",
        "  def maybe_gpu(self, v, gpu):\n",
        "      return v.cuda() if gpu else v\n",
        "\n",
        "  def get_pretrained_embeddings(self, hp):\n",
        "    glove_vectors = GloVe(name=\"6B\", dim=hp['EMBEDDING_DIM'])\n",
        "    EMBEDDING_DIM = glove_vectors.vectors.shape[1]\n",
        "    pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(self.vocab), EMBEDDING_DIM)).astype('f')\n",
        "    pretrained_embeddings[0] = 0\n",
        "    for word, wi in glove_vectors.stoi.items():\n",
        "        try:\n",
        "            pretrained_embeddings[self.word_to_idx[word]-1] = glove_vectors.__getitem__(word)\n",
        "        except KeyError:\n",
        "            pass\n",
        "    pretrained_embeddings = self.maybe_gpu(torch.from_numpy(pretrained_embeddings), hp['USE_GPU'])\n",
        "    return pretrained_embeddings\n",
        "\n",
        "  def get_switcher_model(parent_self):\n",
        "    class Categorizer(nn.Module):\n",
        "      def __init__(self, embedding_dim, vocab_size, label_size, use_gpu):\n",
        "          \"\"\"Prepare individual layers\"\"\"\n",
        "          super(Categorizer, self).__init__()\n",
        "          self.use_gpu = use_gpu\n",
        "          self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "          self.network = nn.Sequential(\n",
        "              nn.Linear(embedding_dim, 100),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(100, 50),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(50, label_size)\n",
        "          )\n",
        "\n",
        "      def forward(self, sentence):\n",
        "          \"\"\"Use the layers of this model to propagate input and return class log probabilities\"\"\"\n",
        "          if self.use_gpu:\n",
        "              sentence = sentence.cuda()\n",
        "          x = self.embeddings(sentence).permute(1, 0, 2)\n",
        "          x = x.mean(dim=0)\n",
        "          output = self.network(x)\n",
        "          return output\n",
        "    return Categorizer\n",
        "\n",
        "  def prepare_model(self, Categorizer, hp, pretrained_embeddings):\n",
        "    num_classes = 5\n",
        "    categorizer = Categorizer(embedding_dim=hp[\"EMBEDDING_DIM\"], vocab_size=len(self.vocab), label_size=num_classes, use_gpu=hp[\"USE_GPU\"])\n",
        "    categorizer.embeddings = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "    model = categorizer\n",
        "    return model\n",
        "\n",
        "  def load_model(self):\n",
        "    hp = {\n",
        "        \"EPOCHS\": 10,\n",
        "        \"BATCH_SIZE\": 16,\n",
        "        \"LEARNING_RATE\": 1e-2,\n",
        "        \"EMBEDDING_DIM\": 50,\n",
        "        \"USE_GPU\": torch.cuda.is_available()\n",
        "    }\n",
        "    pretrained_embeddings = self.get_pretrained_embeddings(hp)\n",
        "    Categorizer = self.get_switcher_model()\n",
        "    self.model = self.prepare_model(Categorizer, hp, pretrained_embeddings)\n",
        "    self.model.load_state_dict(torch.load(self.model_path, map_location=torch.device('cpu')))\n",
        "\n",
        "  def get_prediction(self, text):\n",
        "    with torch.no_grad():\n",
        "      classes = ['audio_to_text_data', 'blog_scrapping', 'random_data', 'resume_summary_data', 'suduko_data']\n",
        "      self.model.eval()\n",
        "      text = self.text_transform([text])\n",
        "      text_tensor = F.to_tensor(text, self.padding_idx)\n",
        "      prediction = self.model(text_tensor)\n",
        "      probs = torch.softmax(prediction, dim=-1)[0].tolist()\n",
        "      final_prediction = list(zip(classes, probs))\n",
        "      final_prediction = sorted(final_prediction, key = lambda x: -x[1])\n",
        "      return final_prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Predictor only once at server start up\n",
        "MODEL_PATH = 'drive/MyDrive/NN.pt'\n",
        "predictor = NN_Predictor(MODEL_PATH)\n",
        "predictor.load_model()"
      ],
      "metadata": {
        "id": "ngW98RSrSS75"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run prediction for each API call\n",
        "predictor.get_prediction('Solve this Sudoku puzzle for me')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q0_WJPxP9J7",
        "outputId": "52bf244e-6f7a-46cd-fa61-69e9c66f3d7a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('suduko_data', 0.9999984502792358),\n",
              " ('audio_to_text_data', 9.453690950067539e-07),\n",
              " ('blog_scrapping', 5.991369675939495e-07),\n",
              " ('random_data', 9.271002854305266e-10),\n",
              " ('resume_summary_data', 4.996553726321906e-10)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}